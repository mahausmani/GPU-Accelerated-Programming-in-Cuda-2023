{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mu06905/GPU-Accelerated-Programming-in-Cuda-2023/blob/main/Week3/Assignment1_Random_Array_Initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBUHmmqQHOS-",
        "outputId": "2865b28b-9401-471f-c31c-967b73438c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-iz6ni8ju\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-iz6ni8ju\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aikKbs6TMEp6",
        "outputId": "a2481fa9-9734-42f4-eabc-192562b3924f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 24 06:35:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name my_curand.cu \n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#define CUDA_CALL(x) do { if((x)!=cudaSuccess) { \\\n",
        "    printf(\"Error at %s:%d\\n\",__FILE__,__LINE__);\\\n",
        "    return EXIT_FAILURE;}} while(0)\n",
        "#define CURAND_CALL(x) do { if((x)!=CURAND_STATUS_SUCCESS) { \\\n",
        "    printf(\"Error at %s:%d\\n\",__FILE__,__LINE__);\\\n",
        "    return EXIT_FAILURE;}} while(0)\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        " \n",
        "int main()\n",
        "{\n",
        "  const int N = 1000000;  \n",
        "  \n",
        "  float* h_data = (float*)malloc(N * sizeof(float));\n",
        "  int start_h = clock();\n",
        "  for(int i=0;i<N;i++)\n",
        "      h_data[i]=rand()%N;\n",
        "  int end = clock();\n",
        "  int time_taken = end - start_h;\n",
        "  printf(\"Time taken to populate data on host is %d ms \\n\",time_taken);\n",
        "  printf(\"fist 10 elements from host\\n\");\n",
        "  for(int i = 0; i<10;i++){\n",
        "      printf(\"d_data[%d] -> %f \\n\",i,h_data[i]);\n",
        "  }\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "  float* d_data;\n",
        "  curandGenerator_t gen;\n",
        "  CUDA_CALL(cudaMalloc((void **)&d_data, N*sizeof(float)));\n",
        "  CURAND_CALL(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n",
        "  CURAND_CALL(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n",
        "  cudaEventRecord(start);\n",
        "  CURAND_CALL(curandGenerateUniform(gen, d_data, N));\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  float milliseconds = 0;\n",
        "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "  printf(\"Time taken to populate data on device is %f ms \\n\",milliseconds);\n",
        "  start_h = clock();\n",
        "  CUDA_CALL(cudaMemcpy(h_data, d_data, N * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  end = clock();\n",
        "  time_taken = end - start_h;\n",
        "  printf(\"time taken to copy data from gpu to cpu is: %i ms \\n\",time_taken);\n",
        "  printf(\"fist 10 elements from device\\n\");\n",
        "  for(int i = 0; i<10;i++){\n",
        "      printf(\"d_data[%d] -> %f \\n\",i,h_data[i]);\n",
        "  }\n",
        "\n",
        "  \n",
        "  free(h_data);  //deallocate memory on device\n",
        "  CURAND_CALL(curandDestroyGenerator(gen));\n",
        "  CUDA_CALL(cudaFree(d_data));\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P71PB1boHhgz",
        "outputId": "a0e4ecd0-e4c8-44b5-c763-81311f907b18"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/my_curand /content/src/my_curand.cu -lcurand"
      ],
      "metadata": {
        "id": "BjpnP8kpQpF2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/my_curand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIDuF6cjQ9-m",
        "outputId": "2ee9c9d9-e82d-4637-d2ef-2264acce4908"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to populate data on host is 9745 ms \n",
            "fist 10 elements from host\n",
            "d_data[0] -> 289383.000000 \n",
            "d_data[1] -> 930886.000000 \n",
            "d_data[2] -> 692777.000000 \n",
            "d_data[3] -> 636915.000000 \n",
            "d_data[4] -> 747793.000000 \n",
            "d_data[5] -> 238335.000000 \n",
            "d_data[6] -> 885386.000000 \n",
            "d_data[7] -> 760492.000000 \n",
            "d_data[8] -> 516649.000000 \n",
            "d_data[9] -> 641421.000000 \n",
            "Time taken to populate data on device is 0.495904 ms \n",
            "time taken to copy data from gpu to cpu is: 960 ms \n",
            "fist 10 elements from device\n",
            "d_data[0] -> 0.145468 \n",
            "d_data[1] -> 0.820181 \n",
            "d_data[2] -> 0.550399 \n",
            "d_data[3] -> 0.294830 \n",
            "d_data[4] -> 0.914733 \n",
            "d_data[5] -> 0.868979 \n",
            "d_data[6] -> 0.321921 \n",
            "d_data[7] -> 0.782857 \n",
            "d_data[8] -> 0.011302 \n",
            "d_data[9] -> 0.285450 \n"
          ]
        }
      ]
    }
  ]
}